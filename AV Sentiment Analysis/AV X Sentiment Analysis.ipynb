{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b03674e-5323-49ef-9d64-891b698fce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All imports\n",
    "# The given file had row 30271 as junk characters, I had to remove that row completely for training\n",
    "\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.util import ngrams as ng\n",
    "from nltk import FreqDist as fd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sacremoses import MosesDetokenizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as twd\n",
    "import string\n",
    "string.punctuation\n",
    "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c5f3d2-4aff-47ed-90ac-bd968e2422c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Iterate over each row in the csv using reader object\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv_reader:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# row variable is a list that represents a row in csv\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m         row\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_train_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m'''def df_create(file1, file2):\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    f1 = pd.read_csv(file1, usecols=[\"label\",\"tweet\"])\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    #f.to_csv(\"final_train_data.csv\", index=False)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03mdf_create(\"train.csv\", \"test_tweets.csv\")'''\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# Read the training using pandas module and select only the sentiment and text columns \n",
    "\n",
    "from csv import reader\n",
    "\n",
    "# open file in read mode\n",
    "with open('train.csv', 'r', encoding=\"utf8\") as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Iterate over each row in the csv using reader object\n",
    "    for row in csv_reader:\n",
    "        # row variable is a list that represents a row in csv\n",
    "        row.to_csv(\"final_train_data.csv\", index=False)\n",
    "\n",
    "'''def df_create(file1, file2):\n",
    "    f1 = pd.read_csv(file1, usecols=[\"label\",\"tweet\"])\n",
    "    #f.to_csv(\"final_train_data.csv\", index=False)\n",
    "    f2 = pd.read_csv(file1, usecols=[\"label\",\"tweet\"])\n",
    "    merged_df = pd.concat([f1, f2], ignore_index=True)\n",
    "    print(merged_df)\n",
    "    #merged_df.to_csv(\"final_train_data.csv\", index=False)\n",
    "    \n",
    "df_create(\"train.csv\", \"test_tweets.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673f0b03-ae89-40d2-9a4d-e1be7b708397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the Tweet Column. \n",
    "\n",
    "global x\n",
    "x = 0\n",
    "def tokenize(content):\n",
    "    return wt(content)\n",
    "\n",
    "def RemoveStopWords(content):\n",
    "    filtered_sentence = []\n",
    "    for w in content:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return (filtered_sentence)\n",
    "\n",
    "def Lemmatize(content):\n",
    "        return(wl.lemmatize(content))\n",
    "\n",
    "def refine(user_string):      \n",
    "    text = user_string\n",
    "    cleaned_user_string = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text_tokens = tokenize(cleaned_user_string)         \n",
    "    removed_stop_words = text_tokens \n",
    "    lemmatized_list = []\n",
    "    for word in removed_stop_words:         \n",
    "        w = Lemmatize(word) \n",
    "        w = str(w)\n",
    "        if (w != \"\"):\n",
    "            lemmatized_list.append(w)\n",
    "    return(lemmatized_list) \n",
    "\n",
    "def AddRefinedDescription(file):\n",
    "    df = pd.read_csv(file)\n",
    "    desc = df['tweet']\n",
    "    refined_d = []\n",
    "    for d in desc:\n",
    "        refined = refine(d)\n",
    "        refined_d.append(refined)\n",
    "    df['preprocessed'] = refined_d\n",
    "    df.to_csv(\"final_train_data.csv\")\n",
    "\n",
    "def TFIDFVectorization(S1):\n",
    "    tf_vect = TfidfVectorizer(min_df=1,lowercase=True)\n",
    "    review_list = [S1]\n",
    "    #print(S1)\n",
    "    global x\n",
    "    x = x + 1\n",
    "    #print(x)\n",
    "    tf_matrix = tf_vect.fit_transform(review_list)\n",
    "    return(tf_matrix.toarray())\n",
    "\n",
    "AddRefinedDescription(\"final_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0825b0ad-fbf5-453d-abed-c6ec87cc420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the Tweet Column for test data\n",
    "\n",
    "global x\n",
    "x = 0\n",
    "def tokenize(content):\n",
    "    return wt(content)\n",
    "\n",
    "def RemoveStopWords(content):\n",
    "    filtered_sentence = []\n",
    "    for w in content:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return (filtered_sentence)\n",
    "\n",
    "def Lemmatize(content):\n",
    "        return(wl.lemmatize(content))\n",
    "\n",
    "def refine(user_string):      \n",
    "    text = user_string\n",
    "    cleaned_user_string = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    return(cleaned_user_string) \n",
    "\n",
    "def AddRefinedDescription(file):\n",
    "    df = pd.read_csv(file)\n",
    "    desc = df['tweet']\n",
    "    refined_d = []\n",
    "    for d in desc:\n",
    "        refined = refine(d)\n",
    "        refined_d.append(refined)\n",
    "    df['preprocessed'] = refined_d\n",
    "    df.to_csv(\"test_tweets_refined.csv\")\n",
    "\n",
    "AddRefinedDescription(\"test_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b57169d-c233-42a5-9a14-9af60b1d6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(file):\n",
    "    df = pd.read_csv(file)\n",
    "    desc = df['preprocessed']\n",
    "    y = df['label']\n",
    "    #count_vect = TfidfVectorizer(min_df=1,lowercase=True,stop_words='english')\n",
    "    count_vect = CountVectorizer(lowercase=True, stop_words='english', min_df=5)\n",
    "    X_counts = count_vect.fit_transform(desc)\n",
    "    #print(X_counts)\n",
    "    X_names = count_vect.get_feature_names_out()\n",
    "    #print(X_names)\n",
    "    X_counts = pd.DataFrame(X_counts.toarray(), columns=X_names)\n",
    "    #print(X_counts)\n",
    "    X_counts.to_csv(\"train_data_final1.csv\", sep=',', encoding='utf-8', index=1, header=True)\n",
    "    #y.to_csv(\"data_final1.csv\", index_label='label')\n",
    "    \n",
    "cm(\"final_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb991f5c-9225-4f22-8aa7-f09bf6b2ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(file):\n",
    "    df = pd.read_csv(file)\n",
    "    desc = df['preprocessed']\n",
    "    #y = df['label']\n",
    "    #count_vect = TfidfVectorizer(min_df=1,lowercase=True,stop_words='english')\n",
    "    count_vect = CountVectorizer(lowercase=True, stop_words='english', min_df=5)\n",
    "    X_counts = count_vect.fit_transform(desc)\n",
    "    #print(X_counts)\n",
    "    X_names = count_vect.get_feature_names_out()\n",
    "    #print(X_names)\n",
    "    X_counts = pd.DataFrame(X_counts.toarray(), columns=X_names)\n",
    "    #print(X_counts)\n",
    "    X_counts.to_csv(\"test_data_final1.csv\", sep=',', encoding='utf-8', index=1, header=True)\n",
    "    #y.to_csv(\"data_final1.csv\", index_label='label')\n",
    "    \n",
    "cm(\"test_tweets_refined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd21f2f9-052b-42a0-bf42-9785c6cd386d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- accused\n- aggressive\n- aging\n- alkalamba\n- ambrose\n- ...\nFeature names seen at fit time, yet now missing:\n- aampe\n- abandoned\n- abc\n- ableism\n- abundance\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy_score(actualValue, predictedValue)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(acc)\n\u001b[1;32m---> 32\u001b[0m run_training(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_data_final1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_train_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(file1, file2)\u001b[0m\n\u001b[0;32m     20\u001b[0m c \u001b[38;5;241m=\u001b[39m MultinomialNB() \n\u001b[0;32m     21\u001b[0m c\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#print(type(y_pred))\u001b[39;00m\n\u001b[0;32m     25\u001b[0m actualValue \u001b[38;5;241m=\u001b[39m y_test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:105\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m    106\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:577\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- accused\n- aggressive\n- aging\n- alkalamba\n- ambrose\n- ...\nFeature names seen at fit time, yet now missing:\n- aampe\n- abandoned\n- abc\n- ableism\n- abundance\n- ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def run_training(file1,file2):\n",
    "    #train, test = train_test_split(df, test_size=0.2)\n",
    "    dfx = pd.read_csv(file1)\n",
    "    #dfy = df['label']\n",
    "    #dfx = df.drop('label', axis=1)\n",
    "    #print(dfx.shape)\n",
    "    #print(dfy.shape)\n",
    "    df = pd.read_csv(file2)\n",
    "    dfy = df['label']\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.2)\n",
    "    X_train = dfx\n",
    "    y_train = dfy\n",
    "    dftest = pd.read_csv(\"test_data_final1.csv\")\n",
    "    X_test = dftest\n",
    "    \n",
    "    #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    c = MultinomialNB() \n",
    "    c.fit(X_train, y_train)\n",
    "    y_pred = c.predict(X_test)\n",
    "    #print(type(y_pred))\n",
    "\n",
    "    actualValue = y_test\n",
    "    predictedValue = y_pred\n",
    "\n",
    "    print(\"Accuracy :\")\n",
    "    acc = accuracy_score(actualValue, predictedValue)\n",
    "    print(acc)\n",
    "\n",
    "run_training(\"train_data_final1.csv\",\"final_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd94cb-0994-48ba-9a65-5b5f3a6f1e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
