{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebd7545-09fb-425a-bcb2-9e9dbc3f1a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Australia', 'England', 'India', 'cricket', 'final', 'match', 'the', 'won'},\n",
       " ['India', 'won', 'the', 'match'],\n",
       " ['England', 'won', 'the', 'cricket', 'match'],\n",
       " ['Australia', 'won', 'the', 'final', 'match'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Make a corpus of 3 sentences\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "\n",
    "def MakeCorpus(S1, S2, S3):\n",
    "    S1_tokens = wt(S1)\n",
    "    S2_tokens = wt(S2)\n",
    "    S3_tokens = wt(S3)\n",
    "    all_tokens = set(S1_tokens).union(set(S2_tokens)).union(set(S3_tokens))\n",
    "    return(all_tokens, S1_tokens, S2_tokens, S3_tokens)\n",
    "\n",
    "S1 = 'India won the match'\n",
    "S2 = 'England won the cricket match'\n",
    "S3 = 'Australia won the final match'\n",
    "MakeCorpus(S1, S2, S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffb2710-a5b0-455e-8ea4-c55492f0a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   the  cricket  Australia  final  England  India  match  won\n",
      "0    1        0          0      0        0      1      1    1\n",
      "1    1        1          0      0        1      0      1    1\n",
      "2    1        0          1      1        0      0      1    1\n"
     ]
    }
   ],
   "source": [
    "#2.Write a program to input three sentences from user and convert them into vectors.    \n",
    "# Use presence and absence of words to build the vectors. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def PresenceAbsenceVectorization(S1, S2, S3):\n",
    "    all_tokens, S1_tokens, S2_tokens, S3_tokens = MakeCorpus(S1, S2, S3)\n",
    "    review1_dict = dict.fromkeys(all_tokens,0)\n",
    "    review2_dict = dict.fromkeys(all_tokens,0)\n",
    "    review3_dict = dict.fromkeys(all_tokens,0)\n",
    "    for token in S1_tokens:\n",
    "        review1_dict[token]+=1\n",
    "    for token in S2_tokens:\n",
    "        review2_dict[token]+=1\n",
    "    for token in S3_tokens:\n",
    "        review3_dict[token]+=1\n",
    "    reviews_Dict_DF = pd.DataFrame([review1_dict,review2_dict,review3_dict])\n",
    "    print(reviews_Dict_DF)\n",
    "    \n",
    "S1 = 'India won the match'\n",
    "S2 = 'England won the cricket match'\n",
    "S3 = 'Australia won the final match'\n",
    "PresenceAbsenceVectorization(S1, S2, S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f70eab-5fa5-4d59-8150-85fed4ea84ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#3  Write a program to enter 3 strings from a user and vectorise them on basis of their counts.   \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def CountVectorization(S1, S2, S3):\n",
    "    review_list = ['tremendous', '100', '%', 'varietal', 'wine', 'hail', 'Oakville', 'aged', 'three', 'year', 'oak', '.', 'Juicy', 'red-cherry', 'fruit', 'compelling', 'hint', 'caramel', 'greet', 'palate', ',', 'framed', 'elegant', ',', 'fine', 'tannin', 'subtle', 'minty', 'tone', 'background', '.', 'Balanced', 'rewarding', 'start', 'finish', ',', 'year', 'ahead', 'develop', 'nuance', '.', 'Enjoy', '2022â€“2030', '.']\n",
    "    count_vect = CountVectorizer()\n",
    "    X_counts = count_vect.fit_transform(review_list)\n",
    "    print(X_counts.toarray())\n",
    "    type(X_counts)\n",
    "    X_names = count_vect.get_feature_names_out()\n",
    "    a = pd.DataFrame(X_counts.toarray(),columns=X_names)\n",
    "    #print(a)\n",
    "\n",
    "S1 = 'India won the match'\n",
    "S2 = 'England won the cricket match'\n",
    "S3 = 'Australia won the final match'\n",
    "CountVectorization(S1, S2, S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d189bd31-5f30-4fbe-84ae-360aa035c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   australia   cricket   england     final     india     match       won\n",
      "0   0.000000  0.000000  0.000000  0.000000  0.767495  0.453295  0.453295\n",
      "1   0.000000  0.608845  0.608845  0.000000  0.000000  0.359594  0.359594\n",
      "2   0.608845  0.000000  0.000000  0.608845  0.000000  0.359594  0.359594\n"
     ]
    }
   ],
   "source": [
    "#4 Write a program to input 3 strings but vectorise them using \n",
    "# TF-IDF (Term Frequency and Inverse Document Frequency) and print the strings along with the vectors. \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def TFIDFVectorization(S1, S2, S3):\n",
    "    tf_vect = TfidfVectorizer(min_df=1,lowercase=True,stop_words='english')\n",
    "    review_list = [S1,S2,S3]\n",
    "    tf_matrix = tf_vect.fit_transform(review_list)\n",
    "    type(tf_matrix)\n",
    "    tf_matrix.shape\n",
    "    tf_names = tf_vect.get_feature_names_out()\n",
    "    tf_df = pd.DataFrame(tf_matrix.toarray(),columns=tf_names)\n",
    "    print(tf_df)\n",
    "\n",
    "S1 = 'India won the match'\n",
    "S2 = 'England won the cricket match'\n",
    "S3 = 'Australia won the final match'\n",
    "TFIDFVectorization(S1, S2, S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125d9dd-35e8-449a-a04d-15ad01dac54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
